{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/harshsojitra007/CE132_ML_Labs/blob/main/ML_Lab_2.ipynb","timestamp":1676968910451}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w05IpL7iluGI","outputId":"26f5e379-1542-4f5e-bfab-95ab77bb32e7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Columns to transform\n","\n"," [[   44 72000]\n"," [   27 48000]\n"," [   30 54000]\n"," [   38 61000]\n"," [   40 68000]\n"," [   35 58000]\n"," [   39 52000]\n"," [   48 79000]\n"," [   50 83000]\n"," [   37 67000]\n"," [   45 55000]]\n","\n","Scaled data\n","\n"," [[0.73913043 0.68571429]\n"," [0.         0.        ]\n"," [0.13043478 0.17142857]\n"," [0.47826087 0.37142857]\n"," [0.56521739 0.57142857]\n"," [0.34782609 0.28571429]\n"," [0.52173913 0.11428571]\n"," [0.91304348 0.88571429]\n"," [1.         1.        ]\n"," [0.43478261 0.54285714]\n"," [0.7826087  0.2       ]]\n","\n","Standardized data\n","\n"," [[ 0.68188156  0.79548755]\n"," [-1.81835082 -1.41513049]\n"," [-1.37713334 -0.86247598]\n"," [-0.2005534  -0.21771238]\n"," [ 0.09359159  0.42705121]\n"," [-0.64177088 -0.49403964]\n"," [-0.05348091 -1.04669415]\n"," [ 1.27017153  1.44025115]\n"," [ 1.56431652  1.80868749]\n"," [-0.34762589  0.33494213]\n"," [ 0.82895405 -0.77036689]]\n","\n","\n","[[0 44 72000]\n"," [2 27 48000]\n"," [1 30 54000]\n"," [2 38 61000]\n"," [1 40 68000]\n"," [0 35 58000]\n"," [2 39 52000]\n"," [0 48 79000]\n"," [1 50 83000]\n"," [0 37 67000]\n"," [2 45 55000]]\n","\n","     France  Germany  Spain\n","0        1        0      0\n","1        0        0      1\n","2        0        1      0\n","3        0        0      1\n","4        0        1      0\n","5        1        0      0\n","6        0        0      1\n","7        1        0      0\n","8        0        1      0\n","9        1        0      0\n","10       0        0      1\n","\n","New Dataset\n","     Age  Salary\n","0    44   72000\n","1    27   48000\n","2    30   54000\n","3    38   61000\n","4    40   68000\n","5    35   58000\n","6    39   52000\n","7    48   79000\n","8    50   83000\n","9    37   67000\n","10   45   55000\n","\n","New Dataset\n","     France  Germany  Spain  Age  Salary\n","0        1        0      0   44   72000\n","1        0        0      1   27   48000\n","2        0        1      0   30   54000\n","3        0        0      1   38   61000\n","4        0        1      0   40   68000\n","5        1        0      0   35   58000\n","6        0        0      1   39   52000\n","7        1        0      0   48   79000\n","8        0        1      0   50   83000\n","9        1        0      0   37   67000\n","10       0        0      1   45   55000\n","\n"," [[1. 0. 0.]\n"," [0. 0. 1.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]\n"," [0. 1. 0.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [0. 1. 0.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]]\n","\n","     Country_0  Country_1  Country_2  Age  Salary Purchased\n","0         1.0        0.0        0.0   44   72000        No\n","1         0.0        0.0        1.0   27   48000       Yes\n","2         0.0        1.0        0.0   30   54000        No\n","3         0.0        0.0        1.0   38   61000        No\n","4         0.0        1.0        0.0   40   68000       Yes\n","5         1.0        0.0        0.0   35   58000       Yes\n","6         0.0        0.0        1.0   39   52000        No\n","7         1.0        0.0        0.0   48   79000       Yes\n","8         0.0        1.0        0.0   50   83000        No\n","9         1.0        0.0        0.0   37   67000       Yes\n","10        0.0        0.0        1.0   45   55000        No\n","\n","\n","\n","New Dataset for missed data\n","\n","     Country   Age   Salary Purchased\n","0    France  44.0  72000.0        No\n","1     Spain  27.0  48000.0       Yes\n","2   Germany  30.0  54000.0        No\n","3     Spain  38.0  61000.0        No\n","5   Germany  40.0      NaN       Yes\n","6    France  35.0  58000.0       Yes\n","7     Spain   NaN  52000.0        No\n","8    France  48.0  79000.0       Yes\n","9   Germany  50.0  83000.0        No\n","10   France  37.0  67000.0       Yes\n","11    Spain  45.0  55000.0        No\n","\n","Replace Null Age with mean\n","\n","     Country   Age   Salary Purchased\n","0    France  44.0  72000.0        No\n","1     Spain  27.0  48000.0       Yes\n","2   Germany  30.0  54000.0        No\n","3     Spain  38.0  61000.0        No\n","5   Germany  40.0      NaN       Yes\n","6    France  35.0  58000.0       Yes\n","7     Spain  39.4  52000.0        No\n","8    France  48.0  79000.0       Yes\n","9   Germany  50.0  83000.0        No\n","10   France  37.0  67000.0       Yes\n","11    Spain  45.0  55000.0        No\n","\n","Replace Null Salary with mean\n","\n","     Country   Age   Salary Purchased\n","0    France  44.0  72000.0        No\n","1     Spain  27.0  48000.0       Yes\n","2   Germany  30.0  54000.0        No\n","3     Spain  38.0  61000.0        No\n","5   Germany  40.0  62900.0       Yes\n","6    France  35.0  58000.0       Yes\n","7     Spain  39.4  52000.0        No\n","8    France  48.0  79000.0       Yes\n","9   Germany  50.0  83000.0        No\n","10   France  37.0  67000.0       Yes\n","11    Spain  45.0  55000.0        No\n"]}],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder, OneHotEncoder\n","from sklearn.impute import SimpleImputer\n","\n","data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Data_for_Transformation.csv\")\n","newX = data.iloc[:, 1:3].values\n","\n","print(\"Columns to transform\\n\\n\", newX)\n","\n","minMaxScaler = MinMaxScaler()\n","standardScaler = StandardScaler()\n","\n","scaledX = minMaxScaler.fit_transform(newX)\n","standardizedX = standardScaler.fit_transform(newX)\n","\n","print(\"\\nScaled data\\n\\n\", scaledX)\n","print(\"\\nStandardized data\\n\\n\", standardizedX)\n","\n","dataCategory = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Data_for_Categorical_Values.csv\")\n","print('\\n')\n","dataCategory.describe()\n","\n","newX = dataCategory.iloc[ : , :-1].values\n","dataCategoryCp = dataCategory\n","\n","labelEncoder = LabelEncoder()\n","newX[ : , 0] = labelEncoder.fit_transform(newX[ : , 0])\n","print(newX)\n","\n","dummyCountries = pd.get_dummies(dataCategory[\"Country\"])\n","print('\\n', dummyCountries)\n","\n","dataCategory = dataCategory.drop(['Country', 'Purchased'], axis=1)\n","print('\\nNew Dataset\\n', dataCategory)\n","dataCategory = pd.concat([dummyCountries, dataCategory], axis=1)\n","print('\\nNew Dataset\\n', dataCategory)\n","\n","oneHotEncoder = OneHotEncoder()\n","x = oneHotEncoder.fit_transform(dataCategoryCp.Country.values.reshape(-1,1)).toarray()\n","print('\\n', x)\n","\n","dfOneHot = pd.DataFrame(x, columns=[\"Country_\" + str(int(i)) for i in range(dataCategoryCp.shape[1] - 1)])\n","dataFrame = pd.concat([dfOneHot, dataCategoryCp], axis=1)\n","dataFrame = dataFrame.drop(['Country'], axis=1)\n","print('\\n', dataFrame)\n","\n","dataMiss = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Data_for_Missing_Values.csv\")\n","print('\\n')\n","dataMiss.describe()\n","\n","dataMiss.dropna(axis=0, how=\"all\", inplace=True)\n","print('\\nNew Dataset for missed data\\n\\n', dataMiss)\n","\n","updatedDataMiss = dataMiss\n","updatedDataMiss['Age'] = updatedDataMiss['Age'].fillna(updatedDataMiss['Age'].mean())\n","print('\\nReplace Null Age with mean\\n\\n', updatedDataMiss)\n","\n","updatedDataMiss['Salary'] = updatedDataMiss['Salary'].fillna(updatedDataMiss['Salary'].mean())\n","print('\\nReplace Null Salary with mean\\n\\n', updatedDataMiss)"]}]}